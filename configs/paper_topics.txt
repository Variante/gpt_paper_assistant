 1. New methodological improvements to self-supervised learning for better image or video representation learning related to robotics. 
    - Relevant: papers that discuss specific methods like self-supervised learning, contrastive learning, masked autoencoder, improving these methods, or analyzing them. Usually, these papers will explicitly mention self-supervised learning, representation learning, and so on.
    - Not relevant: papers about adaptation to some task. Simply following instructions or inputs are not sufficient.
 2. Shows new applications of vision language models (VLMs) in robotics like reinforcement learning or imitation learning.
    - Relevant: papers take advantage of vision language models to solve open robotics tasks like a novel task demonstrated or requested by users.
    - Not relevant: any papers that do not consider language models in robotics.
 3. Shows new network architecture, module, auxiliary loss, training method when perform reinforcement learning, imitation learning or general robotics topic.
    - Relevant: papers use sequential models or a diffusion model to learn a robot policy.
    - Not relevant: any papers introduce new robot hardwards to solve specific problems or a particular application of a certain policy learning method.
 4. Shows a significant advance in the performance of text to image, text to video, image to video diffusion models, or diffusion model for 3D model generation.
    - Relevant: papers that improve diffusion models for better generation results, papers that reduce the computational cost of a diffusion model in terms of inference and training, and papers study the image quality generated by the diffusion model.
    - Not relevant: papers about language diffusions.
 5. Papers on video segmentation that rely on unsupervised and self-supervised learning methods.
    - Relevant: Methods with applications to video object segmentation and video semantic segmentation showing experiments on current and new benchmarks.
    - Not relevant: Application of existing methods to  specialized domains such as medicine, satellites or agriculture with only a slight tweak to the method.
 6. Papers on transfer learning between modalities such as audio to video, optical flow to video, language to video and image to video; these papers should consider how to use domain-agnostic data to improve performance on videos.
    - Relevant: Methods that focus on maintaining spatial detail in representations, especially for dense prediction tasks.
    - Not relevant: Image classification, video action recognition and other tasks that do not require pixel-wise understanding.

 In suggesting papers to your friend, remember that he enjoys papers on self-supervised learning, policy learning, vision language models, and generative models in computer visions.
 Your friend also enjoys papers on video segmentation and exploration on transfer learning between modalities.
 Your friend also likes learning about surprising empirical results in language models, as well as clever statistical tricks.
 He does not want to read papers that are about primarily applications of methods to specific domains.
